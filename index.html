<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Dog Identification App</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      line-height: 1.6;
      background-color: #f4f4f4;
      margin: 0;
      padding: 0;
    }

    header {
      background-color: #333;
      color: white;
      padding: 10px 0;
      text-align: center;
    }

    nav ul {
      display: flex;
      justify-content: center;
      list-style: none;
      padding: 0;
    }

    nav ul li {
      margin: 0 20px;
    }

    nav ul li a {
      color: white;
      text-decoration: none;
    }

    section {
      padding: 20px;
      background-color: white;
      margin: 20px auto;
      max-width: 1000px;
      border-radius: 8px;
      box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
    }

    .section-title {
      font-size: 24px;
      margin-bottom: 10px;
    }

    .image-gallery {
      display: flex;
      flex-wrap: wrap;
      justify-content: space-between;
    }

    .image-gallery img {
      max-width: 48%;
      margin-bottom: 10px;
      border-radius: 8px;
      border: 2px solid #ddd;
    }

    footer {
      background-color: #333;
      color: white;
      text-align: center;
      padding: 10px 0;
      position: fixed;
      width: 100%;
      bottom: 0;
    }
  </style>
</head>

<body>
  <header>
    <h1>Dog Identification App</h1>
    <nav>
      <ul>
        <li><a href="#datasets">Datasets</a></li>
        <li><a href="#results">Results</a></li>
        <li><a href="#model">Model Explanation</a></li>
        <li><a href="#comparison">Model Comparison</a></li>
      </ul>
    </nav>
  </header>

  <section id="datasets">
    <h2 class="section-title">Datasets</h2>
    <p>The Dog Identification App uses two main datasets:</p>
    <ul>
      <li><a href="https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip" target="_blank">Dog Image Dataset (Udacity)</a>: This dataset consists of images of dogs from 133 different breeds. Download and extract to use in training.</li>
      <li><a href="https://drive.google.com/file/d/18haFZAdGo4TTlPI_cwpN8t5RcqJh8ECG/view?usp=sharing" target="_blank">Preprocessed VGG16 Bottleneck Features</a>: This file contains precomputed bottleneck features using the VGG16 model for faster training.</li>
    </ul>
    <div>
      <img src="./Dog_Breeds_Overview.png" alt="Dog Breeds Overview" style="width: 50%;">
    </div>
  </section>

  <section id="results">
    <h2 class="section-title">Results</h2>
    <p>Below are some examples of predictions made by the Dog Identification App:</p>
    <div class="image-gallery">
      <img src="./Predicted_Breed_Chihuahua.png" alt="Predicted Breed: Chihuahua" style="width: 45%;">
      <img src="./Predicted_Breed_Great_Pyrenees_Bernese_Mountain_Dog.png" alt="Predicted Breed: Great Pyrenees and Bernese Mountain Dog" style="width: 45%;">
    </div>
  </section>

  <section id="model">
    <h2 class="section-title">Model Explanation</h2>
    <p>The Dog Identification App uses a convolutional neural network (CNN) with pre-trained VGG16 layers for feature extraction. The extracted features are then passed to a custom classifier that predicts the breed of the dog. Below is a summary of the model:</p>
    <ul>
      <li><strong>VGG16 Feature Extraction:</strong> The convolutional layers of the VGG16 model (pre-trained on ImageNet) are used to extract bottleneck features from the input images.</li>
      <li><strong>Custom Classifier:</strong> The extracted features are passed to a custom-built classifier with several dense layers and a softmax output, which predicts one of the 133 dog breeds.</li>
      <li><strong>Training Process:</strong> The model was trained using the Udacity Dog Images Dataset, with additional preprocessed features to improve efficiency.</li>
    </ul>
  </section>

  <section id="comparison">
    <h2 class="section-title">Model Comparison</h2>
    <p>The Dog Identification App was trained using two different neural network architectures: a custom CNN and a pretrained VGG16 model. Below is a comparison of their performance:</p>

    <h3>Custom CNN Model</h3>
    <p>The custom CNN model was built from scratch and achieved the following performance:</p>
    <img src="./Training_Validation_Accuracy_Loss.png" alt="Training and Validation Results - Custom CNN" style="width: 70%;">
    <p>Though the custom CNN model improved during training, the validation performance showed significant fluctuations, suggesting generalization challenges.</p>

    <h3>VGG16 Model</h3>
    <p>The VGG16 model, pre-trained on ImageNet, was fine-tuned for the dog breed classification task. It achieved better performance and more stable validation results:</p>
    <img src="./training_validation_accuracy_loss_vgg.png" alt="Training and Validation Results - VGG16" style="width: 70%;">
    <p>The VGG16 model outperformed the custom CNN due to its powerful feature extraction capabilities from the pretrained convolutional layers.</p>

    <h3>Key Observations:</h3>
    <ul>
      <li><strong>Accuracy:</strong> The VGG16 model reaches a much higher accuracy (~70%) compared to the custom CNN, which peaks at around 20%.</li>
      <li><strong>Loss:</strong> The VGG16 model stabilizes the validation loss effectively, avoiding overfitting, while the custom CNN struggles with more erratic loss patterns during validation.</li>
      <li><strong>Generalization:</strong> VGG16 demonstrates a higher capacity to generalize across unseen data, making it the superior model in this comparison.</li>
    </ul>
  </section>

  <footer>
    <p>&copy; 2024 Dog Identification App by Yuyao Wang</p>
  </footer>
</body>

</html>
